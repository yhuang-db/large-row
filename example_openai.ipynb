{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/04 12:39:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "test_file = \"10_cols_1_mb\"\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"LargeRowBenchmark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- json_0: struct (nullable = true)\n",
      " |    |-- ended: boolean (nullable = true)\n",
      " |    |-- length: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- json_1: struct (nullable = true)\n",
      " |    |-- ended: boolean (nullable = true)\n",
      " |    |-- length: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- json_2: struct (nullable = true)\n",
      " |    |-- ended: boolean (nullable = true)\n",
      " |    |-- length: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- json_3: struct (nullable = true)\n",
      " |    |-- ended: boolean (nullable = true)\n",
      " |    |-- length: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- json_4: struct (nullable = true)\n",
      " |    |-- ended: boolean (nullable = true)\n",
      " |    |-- length: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- json_5: struct (nullable = true)\n",
      " |    |-- ended: boolean (nullable = true)\n",
      " |    |-- length: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- json_6: struct (nullable = true)\n",
      " |    |-- ended: boolean (nullable = true)\n",
      " |    |-- length: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- json_7: struct (nullable = true)\n",
      " |    |-- ended: boolean (nullable = true)\n",
      " |    |-- length: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- json_8: struct (nullable = true)\n",
      " |    |-- ended: boolean (nullable = true)\n",
      " |    |-- length: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |-- json_9: struct (nullable = true)\n",
      " |    |-- ended: boolean (nullable = true)\n",
      " |    |-- length: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    id|              json_0|              json_1|              json_2|              json_3|              json_4|              json_5|              json_6|              json_7|              json_8|              json_9|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|255000|{true, 134, Is th...|{true, 134, Is th...|{true, 134, Is th...|{true, 134, Is th...|{true, 134, Is th...|{true, 134, Is th...|{true, 134, Is th...|{true, 134, Is th...|{true, 134, Is th...|{true, 134, Is th...|\n",
      "|255001|{true, 713, Clint...|{true, 713, Clint...|{true, 713, Clint...|{true, 713, Clint...|{true, 713, Clint...|{true, 713, Clint...|{true, 713, Clint...|{true, 713, Clint...|{true, 713, Clint...|{true, 713, Clint...|\n",
      "|255002|{true, 173, House...|{true, 173, House...|{true, 173, House...|{true, 173, House...|{true, 173, House...|{true, 173, House...|{true, 173, House...|{true, 173, House...|{true, 173, House...|{true, 173, House...|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(f\"data/openai/parquet/{test_file}.parquet\")\n",
    "df.createOrReplaceTempView(\"T\")\n",
    "df.printSchema()\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(length(json_0.text)=1048576),\n",
       " Row(length(json_0.text)=1048576),\n",
       " Row(length(json_0.text)=1048576),\n",
       " Row(length(json_0.text)=1048576),\n",
       " Row(length(json_0.text)=1048576),\n",
       " Row(length(json_0.text)=1048576),\n",
       " Row(length(json_0.text)=1048576),\n",
       " Row(length(json_0.text)=1048576),\n",
       " Row(length(json_0.text)=1048576),\n",
       " Row(length(json_0.text)=1048576)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1. get the length of structure's long string\n",
    "spark.sql(\"SELECT length(json_0['text']) FROM T\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|    id|              json_0|\n",
      "+------+--------------------+\n",
      "|255002|{true, 173, House...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2. find word in structure's long string\n",
    "spark.sql(\"SELECT id, json_0 FROM T WHERE contains(json_0['text'], 'House')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|  lower(json_0.text)|\n",
      "+--------------------+\n",
      "|is this restauran...|\n",
      "|clinton talks abo...|\n",
      "|house majority wh...|\n",
      "|insight course: l...|\n",
      "|by jennie mcnulty...|\n",
      "|the buddha's teac...|\n",
      "|as part of a broa...|\n",
      "|the atlanta falco...|\n",
      "|front page torren...|\n",
      "|they have changed...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3. lowercase the structure's long string\n",
    "spark.sql(\"SELECT lower(json_0['text']) FROM T\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(word_count(json_0.text)='{specialty=2048, be=2048, hidden=1024, Could=2048, market?=2048, considered=2048, Yes=17408, for=4096, Is=8193, UnsureIs=1024, restaurant?=2048, good=4096, primarily=1024, gem=1024, dinner?=2048, waiIs=1023, mid-range=2048, and=2048, waiters=2048, have=2048, prices=2048, wai=1, moderate?=2048, Unsure=16384, a=6144, No=17408, path?=1024, or=1024, bakery=1024, restaurant=13312, this=18432, off-the-beaten=1024, Japanese=2048, food=2048, /=2048, accept=2048, the=2048, at=2048, reservations=2048, Are=2048, family-friendly=2048, Does=4096, location=2048, lunch?=2048, waitresses=1024, ?=6144}'),\n",
       " Row(word_count(json_0.text)='{told=1024, crowd=2048, allowed=1024, York,=1024, about=1024, whole=1024, sick=2048, during=1024, Day,=1024, muchClinton=1023, tried=1024, music=1024, would=1024, her=5120, Continued=1024, Story=1024, 11=1024, in=1024, ordinary=1024, is=1024, it=2048, being=1024, an=1024, I\\'m=1024, former=1024, debuting=1024, at=3072, even=2048, circumstances,=1024, Sept.=1024, much=1, diagnosed=1024, telling=1024, \"And=1024, maybe=1024, Chappaqua,=1024, I=1024, two=1024, The=1024, secretary=1024, power=1024, after=2048, event=1024, so=1024, illness=1024, a=2048, James=1024, \"I=2048, Good,\"=1024, great=1024, disclose=1024, the=9216, stage=1024, Thursday=1024, Hillary=1024, state,=1024, days=3072, to=7168, under=1024, returned=1024, anniversary=1024, did=2048, attacks.=1024, but=2048, through=1024, New=1024, forced=1024, had=1024, do=1024, Greensboro,=1024, 15th=1024, that=2048, trail=1024, late=1024, leave=1024, intro=1024, me=1024, only=1024, few=1024, North=1024, took=1024, new=1024, months=1024, last=1024, this=1024, \\'reflection\\'=1024, Clinton=2049, Carolina,=1024, \"reconnect=1024, afternoon,=1024, she=1024, Sunday=1024, commemorating=1024, campaign=3072, who=1024, Below=1024, some=1024, week=2048, beginning=1024, about.\"=1024, terrorist=1024, pneumonia.=2048, not=2048, admit=1024, and=2048, easy,=1024, of=6144, talks=1024, just=1024, early=1024, on=1024, good,\"=1024, rest=1024, pretty=1024, chance=1024, spent=1024, Feel=1024, go=1024, was=2048, Election=1024, home=2048, with=3072, what=1024, Her=1024, Brown\\'s=1024, initially=1024, until=1024, time=1024, sitting=1024, taking=1024}'),\n",
       " Row(word_count(json_0.text)='{practice=1024, been=2048, statement:=1024, Center.=1024, outpouring=1024, Republican=1024, completing=1024, during=2048, good=1024, his=3072, Virginia.=1024, discharged=3072, from=5120, Hospital=2048, has=3072, He=3072, intensive=2048, Scalise=3072, trauma=1024, appreciates=1024, period=2048, excellent=1024, in=3072, work=1024, made=1024, time.House=1024, this=1024, received=1024, spirits=1024, is=3072, House=1, an=1024, as=2048, once=1024, rehabilitation.\"=1024, plans=1024, gunshot=2048, doctors,=1024, completes=1024, looking=1024, baseball=1024, support=1024, prayers=1024, care=1024, full=1024, Congress=1024, other=1024, congressional=1024, weeks=3072, beginning=1024, for=1024, recovery=1024, rehabilitation.=2048, Washington=2048, The=2048, wound=2048, are=1024, and=5120, attack=1024, now=1024, of=4096, Yesterday,=1024, aftHouse=1023, after=2048, hospital=2048, MedStar=2048, Congressman=1024, on=1024, Majority=2048, sustaining=1024, grateful=1024, a=4096, Center=1024, six=3072, life-threatening=2048, nurses,=1024, forward=1024, inpatient=2048, was=1024, ago.=1024, also=1024, staff=1024, team=1024, aft=1, the=6144, Whip=2048, Steve=3072, well=1024, progress=1024, to=4096, family=2048, he=3072, return=2048, \"a=1024}'),\n",
       " Row(word_count(json_0.text)='{been=1024, tool,=1024, bring=1024, Course:=1024, reliable=1024, secret,=1024, trip=1024, far=1024, deepest=2048, rabbit=1024, understanding=1024, planet.=1024, you=4096, 14=1024, impact=1024, lesson=1024, is=3072, personal=2048, it=3072, piss=1024, Lesson=1024, benefit=1024, some,=1024, as=3072, at=2048, Are=1024, explored=1024, sophisticated=1024, be=3072, vitally=1024, another=1024, facing=1024, kinds=1024, our=3072, gain=1024, control\"=1024, challenges,=1024, The=2048, how=1024, world=1024, top=1024, are=1024, Mind=1024, have=3072, term=1024, a=1024, mind=1024, implications=1024, set=1024, may=1024, explore=2048, discussed=1024, \"mind=1024, the=10240, information=2048, to=3072, ~=1024, first=1024, but=1024, others.=1024, almost=1024, own=1024, used=2048, good=1024, down=1024, Gloria=1024, healing=1024, amazing=1024, that=1024, hole?=1024, free,=1024, out.=1024, major=1024, This=1024, Insight=1, has=1024, up=1024, us=1024, Though=1024, possibly=1024, which=1024, all=4096, feelings.=1024, invited=1024, this=2048, off.=1024, expense=1024, important=1024, most=1024, These=1024, techniques=1024, Now=1024, topic=1024, some=3072, for=3072, Yet=1024, Steinem=1024, we=1024, can=2048, Control=1024, operations=1024, disturbing=1024, and=2048, ready=1024, of=9216, end=1024, applications.=1024, highly=1024, on=1025, carried=1024, thoughts=1024, or=1024, will=3072, also=2048, control=1024, First,=1024, any=1024, with=1024, lesson.=1024, what=1024, truth=1024, onInsight=1023, challenge=1024, deeper=1024, time=1024, wild=1024, applications=1024}'),\n",
       " Row(word_count(json_0.text)='{named=1024, them,=2048, McNulty=1024, bag=1024, your=2048, Meanwhile,=1024, flawed.\"=1024, lost=1024, Then=2048, severely=1024, case=1024, you=2048, 10=1024, began=1024, made=1024, Curve=1024, Make=1024, groping=2048, lesbian=1024, Top=1024, tiny=2048, be=1024, The=2048, BY=1, came=1024, place=1024, JailBY=1023, But=2048, a=2048, comedians.BY=1024, one=2048, Had=3072, Charlie,=2048, They=1024, the=7168, Spacey,=2048, Lauer=2048, quit=1024, to=5120, All=1024, groper=1024, cop=1024, feel=2048, had=2048, do=2048, harmful=2048, that=2048, Moore=2048, his=1024, all?=2048, Enjoy=1024, should=1024, Jail=1025, say:=1024, Franken=2048, buddies=1024, us=1024, those=2048, all=2048, JENNIE=2048, like=1024, For=2048, Lesbian.com=2048, most=2048, fraud=1024, Tambor,=2048, know=2048, recall,=2048, land.=1024, Roy=2048, Jennie=1024, careers;=1024, racketeer.=1024, Louis=2048, gasbag=2048, some=2048, Christmas=1024, plea,=1024, hands,=2048, media=1024, Donald=4096, ball=1024, penitentiary.=1024, MCNULTY=2048, \"Donald=1024, and=14336, of=4096, gas=1024, Weinstien=2048, lies=1024, foggy=1024, Mueller=1024, deals,=1024, predator=2048, was=1024, perverts=1024, he\\'d=1024, really=2048, magazine\\'s=1024, Screws=1024, eve,=1024, sleaze=1024, You=2048}'),\n",
       " Row(word_count(json_0.text)='{sequence:The=1024, them,=1024, Buddha\\'s=2048, considered=1024, recorder.=1024, Bodhi=2048, President=1024, tape=1024, record=1024, Society,=1024, ten=1024, you=2048, they=1024, years,=1024, using=1024, large=1024, in=3072, distributed=1024, is=1024, them=2048, Buddhism.=1024, an=1024, enthusiastic=1024, as=2048, CDs=1024, at=3072, anyone=1024, teachings=1024, gave=1024, must=1024, Vihara,=2048, be=2048, Bhante=1024, In=3072, Gunaratana,=1024, Buddhist=3072, fundamental=1024, recommend=1024, Is=2048, It=2048, An=1024, summer=1024, Washington=2048, The=1025, sold.=1024, As=2048, fall=2048, are=1024, freely.=1024, domain\"=1024, have=1024, \"public=1024, copy=1024, distribute=2048, so=1024, a=2048, set=1024, could=1024, one=1024, reproduced=1024, continued=1024, distribution.=1024, supporter=1024, They=1024, the=15360, series=1024, to=4096, Bhikkhu=1024, first=1024, Vihara=2048, quantities=1024, had=1024, cassette=1024, while=2048, listen=2048, Teaching=2048, that=3072, copies=1024, nonprofessional=1024, his=1024, lay=1024, Ven.=2048, 1979,=2048, condition=1024, Early=1024, ordinary,=1024, basement=1024, tapes.=1024, for=3072, proper=1024, their=1024, WaThe=1023, not=1024, expanded=1024, and=3072, of=8192, on=2048, over=1024, living=2048, 1981,=1024, lectures=3072, Wa=1, recorded=1024, We=1024, master=1024, twenty-five=1024, suggested=1024, time=2048, he=1024}'),\n",
       " Row(word_count(json_0.text)='{offense=1024, streets=1024, Interior=1024, promised=1024, hell=1024, number=1024, President=1024, measures=2048, punishable=1024, draft=1024, broad=1024, if=1024, victims=2048, limitations=1024, years,=1024, give=1024, issue=1024, Violence=1024, in=1024, …=1024, Elimination=1024, is=1024, France,\"=1024, it=1024, safely,=1024, an=3072, plans=1024, fines=1024, creating=1024, police—measures=1024, 20=1024, statute=1024, sexual=2048, women=2048, become=1024, demand\"=1024, assault=1024, be=1024, In=1024, The=1024, rape=2048, As=1025, French=1024, attack=1024, get=1024, by=1024, 30=1024, include=1024, Against=1024, a=6144, Emmanuelle=1024, may=2048, initial=1024, France24=1024, right=1024, lead=1024, the=9216, help=1024, police=1024, speech=1024, future=1024, insults\"=1024, report=1024, to=9216, Day=1024, \"on=1024, Ministry=1024, assault,=1024, launched=1024, \"We=1024, that=3072, his=1024, outlined=1024, online.=1024, should=1024, few=1024, implement=1024, from=1024, has=1024, which=1024, new=1024, law=2048, minors=1024, like=1024, complaints=1024, Macron=3072, verbal=1024, time.\"=1024, consultations=1024, harassment=1024, reports,=1024, weeks\\'=1024, \"in=1024, part=1024, for=4096, fo=1, their=1024, effort=1024, combat=1024, not=1024, Women.=1024, and=2048, \"gender-based=1024, of=7168, make=3072, on=2048, International=1024, initiative=1024, woman,\"=1024, will=4096, said.=2048, also=1024, foAs=1023, allowing=1024, home=1024, noted=1024, marking=1024, service=1024, there=1024, easier=1024, he=2048, extending=1024, law.=1024, \"The=1024}'),\n",
       " Row(word_count(json_0.text)='{been=1024, fan,\"=1024, streets=1024, Waters,=1024, Braves=1024, what\\'s=1024, ESPN=1024, when=1024, Julio=2048, Matt=2048, season=3072, asking:=1024, having=2048, receiver=2048, in=2048, them=2048, is=3072, ESPN\\'s=2048, I\\'m=1024, ever=1024, Quarterback=2048, See=1024, as=2048, trying=1024, Falcons=6144, Where=1024, coach=2048, Hawks=1024, be=1024, The=1, Jones=2048, asked=1024, are=1024, fan,=1024, have=2048, done.=1024, you\\'ve=1024, man=2048, However,=1024, a=4096, seemed=1024, one=2048, \"I=1024, South=2048, TaThe=1023, started=2048, team=1024, too.=2048, 16-0.=1024, ...=1024, Dan=2048, the=17408, When=1024, Quinn.=2048, \"When=1024, to=5120, under=2048, Power=1024, happiest=1024, Index=1024, NFC=2048, correspondent,=1024, while=2048, Ta=1, find=1024, than=1024, beat=2048, quite=2048, finish=1024, has=3072, which=1024, all=1024, new=2048, fans,=1024, yards=2048, most=2048, walked=1024, below:The=1024, fans?=1024, And=2048, Saints,=2048, support=1024, Take,\"=1024, \"First=2048, full=1024, start,=2048, according=2048, baby.\"=1024, best=1024, video=1024, we=2048, head=2048, Atlanta=3072, and=1024, of=1024, 4-0=2048, said=1024, chance=1024, said.=1024, Football=1024, with=1024, Fan=1024, said:=1024, Ryan=2048, 2015=2048, Reese=1024, Saints=1024, easier=1024, passing=2048}'),\n",
       " Row(word_count(json_0.text)='{+5,=1024, (COMIC=2048, Front=1024, Issho=2048, [スピリタス太郎]=2048, yo=2048, participating=1024, Page]=1024, you=2048, more...=1024, [英訳]=2048, Anony12788=1024, mrwayne=1024, +=2048, ,=12288, Galleries=2048, 2018,=2048, 1=1024, 5=2048, Torrents=2048, Favorites=2048, May=2048, MomentoMori009=1024, The=1024, JSCK=2048, Vol.5=2048, Forums=2048, have=2048, comments.=2048, 31=2048, Lost=1024, Together=2048, Bounties=2048, +2=1024, +5=1024, 一緒にいてよ=2048, +6=2048, +7=1024, +8=1024, +9=1024, the=1024, =CW=2048, Tarou]=2048, Toplists=2048, [Spiritus=2048, to=3072, Ite=2048, |=2048, register=2048, (コミックジェシカ=2048, 2016年7月号)=2048, UTC=2048, before=3072, THDragon=1024, Posted=2048, Page=2048, +11=2048, +14=2048, Drake68655=1024, MechWarriorNY=1024, Light=1024, uploading=1024, SW_CGF=1024, firedragon89=1024, add=2048, read=1024, this=1024, Terms=1024, -6=1024, Please=1024, [English]=2048, nodire=1024, ni=2048, by:=2048, RedResistance=1024, 2016-07)=2048, My=4096, content=1024, TLL==2048, With=2048, can=2048, [Front=1024, and=1024, of=1024, News=2048, site.Front=1024, Home=2048, on=2048, Ice_Cream=1024, or=1024, kiwino=2048, Service=1024, 08:58=2048, any=1024, Base=1024, with=1024, Vol.=2048, Wiki=2048, HentaiVerse=2048, You=4096}'),\n",
       " Row(word_count(json_0.text)=\"{but=8192, concerned=4096, happy=4096, sound=4096, about=4096, I=4096, figured=4096, happy,=4096, that=4096, She=4096, can=4096, file=4096, are=4096, by=4096, get=4096, email,=5120, have=5120, they=4096, live=4096, you=4096, us=9216, a=8192, making=4096, still=4096, complaint.=4096, didn't=4096, navigating=4096, out,=4096, it=4096, menu=5120, They=1024, the=5120, they?They=4096, phone=5120, person=4096, deflect=5120, try=5120, aren't=4096, to=19456, changed=5120}\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4. UDF: count word frequency in structure's long string\n",
    "def word_count(text):\n",
    "    word_count = {}\n",
    "    for word in text.split():\n",
    "        if word in word_count:\n",
    "            word_count[word] += 1\n",
    "        else:\n",
    "            word_count[word] = 1\n",
    "    return word_count\n",
    "\n",
    "\n",
    "spark.udf.register(\"word_count\", word_count)\n",
    "spark.sql(\"SELECT word_count(json_0['text']) FROM T\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
